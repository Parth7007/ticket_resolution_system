{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cdfff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4b14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\ticket_system\\\\ML_model\\\\datasets\\\\merged_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeed9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"subject\"].fillna('') + \" \" + df[\"body\"].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f86ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"subject\"].fillna('') + \" \" + df[\"body\"].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ee6f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>answer</th>\n",
       "      <th>type</th>\n",
       "      <th>priority</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wesentlicher Sicherheitsvorfall</td>\n",
       "      <td>Sehr geehrtes Support-Team,\\n\\nich möchte eine...</td>\n",
       "      <td>Vielen Dank für die Meldung des kritischen Sic...</td>\n",
       "      <td>Incident</td>\n",
       "      <td>high</td>\n",
       "      <td>['Security', 'Outage', 'Disruption', 'Data Bre...</td>\n",
       "      <td>Wesentlicher Sicherheitsvorfall Sehr geehrtes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Account Disruption</td>\n",
       "      <td>Dear Customer Support Team,\\n\\nI am writing to...</td>\n",
       "      <td>Thank you for reaching out, &lt;name&gt;. We are awa...</td>\n",
       "      <td>Incident</td>\n",
       "      <td>high</td>\n",
       "      <td>['Account', 'Disruption', 'Outage', 'IT', 'Tec...</td>\n",
       "      <td>Account Disruption Dear Customer Support Team,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Query About Smart Home System Integration Feat...</td>\n",
       "      <td>Dear Customer Support Team,\\n\\nI hope this mes...</td>\n",
       "      <td>Thank you for your inquiry. Our products suppo...</td>\n",
       "      <td>Request</td>\n",
       "      <td>medium</td>\n",
       "      <td>['Product', 'Feature', 'Tech Support']</td>\n",
       "      <td>Query About Smart Home System Integration Feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inquiry Regarding Invoice Details</td>\n",
       "      <td>Dear Customer Support Team,\\n\\nI hope this mes...</td>\n",
       "      <td>We appreciate you reaching out with your billi...</td>\n",
       "      <td>Request</td>\n",
       "      <td>low</td>\n",
       "      <td>['Billing', 'Payment', 'Account', 'Documentati...</td>\n",
       "      <td>Inquiry Regarding Invoice Details Dear Custome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Question About Marketing Agency Software Compa...</td>\n",
       "      <td>Dear Support Team,\\n\\nI hope this message reac...</td>\n",
       "      <td>Thank you for your inquiry. Our product suppor...</td>\n",
       "      <td>Problem</td>\n",
       "      <td>medium</td>\n",
       "      <td>['Product', 'Feature', 'Feedback', 'Tech Suppo...</td>\n",
       "      <td>Question About Marketing Agency Software Compa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "0                    Wesentlicher Sicherheitsvorfall   \n",
       "1                                 Account Disruption   \n",
       "2  Query About Smart Home System Integration Feat...   \n",
       "3                  Inquiry Regarding Invoice Details   \n",
       "4  Question About Marketing Agency Software Compa...   \n",
       "\n",
       "                                                body  \\\n",
       "0  Sehr geehrtes Support-Team,\\n\\nich möchte eine...   \n",
       "1  Dear Customer Support Team,\\n\\nI am writing to...   \n",
       "2  Dear Customer Support Team,\\n\\nI hope this mes...   \n",
       "3  Dear Customer Support Team,\\n\\nI hope this mes...   \n",
       "4  Dear Support Team,\\n\\nI hope this message reac...   \n",
       "\n",
       "                                              answer      type priority  \\\n",
       "0  Vielen Dank für die Meldung des kritischen Sic...  Incident     high   \n",
       "1  Thank you for reaching out, <name>. We are awa...  Incident     high   \n",
       "2  Thank you for your inquiry. Our products suppo...   Request   medium   \n",
       "3  We appreciate you reaching out with your billi...   Request      low   \n",
       "4  Thank you for your inquiry. Our product suppor...   Problem   medium   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['Security', 'Outage', 'Disruption', 'Data Bre...   \n",
       "1  ['Account', 'Disruption', 'Outage', 'IT', 'Tec...   \n",
       "2             ['Product', 'Feature', 'Tech Support']   \n",
       "3  ['Billing', 'Payment', 'Account', 'Documentati...   \n",
       "4  ['Product', 'Feature', 'Feedback', 'Tech Suppo...   \n",
       "\n",
       "                                                text  \n",
       "0  Wesentlicher Sicherheitsvorfall Sehr geehrtes ...  \n",
       "1  Account Disruption Dear Customer Support Team,...  \n",
       "2  Query About Smart Home System Integration Feat...  \n",
       "3  Inquiry Regarding Invoice Details Dear Custome...  \n",
       "4  Question About Marketing Agency Software Compa...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b738c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68abb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_type = LabelEncoder()\n",
    "le_priority = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "083de6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type_label\"] = le_type.fit_transform(df[\"type\"])\n",
    "df[\"priority_label\"] = le_priority.fit_transform(df[\"priority\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19e583b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_type, test_type, train_priority, test_priority = train_test_split(\n",
    "    df[\"text\"], df[\"type_label\"], df[\"priority_label\"], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44668eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ticket_system\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fb2d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8a8b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TicketDataset(Dataset):\n",
    "    def __init__(self, texts, labels1, labels2):\n",
    "        self.encodings = tokenizer(texts.tolist(), truncation=True, padding=True, max_length=256)\n",
    "        self.labels1 = labels1\n",
    "        self.labels2 = labels2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels1\"] = torch.tensor(self.labels1[idx])\n",
    "        item[\"labels2\"] = torch.tensor(self.labels2[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d982f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TicketDataset(train_texts, train_type.values, train_priority.values)\n",
    "test_dataset = TicketDataset(test_texts, test_type.values, test_priority.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec8e4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81947706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskBERT(nn.Module):\n",
    "    def __init__(self, num_labels1, num_labels2):\n",
    "        super(MultiTaskBERT, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier1 = nn.Linear(self.bert.config.hidden_size, num_labels1)\n",
    "        self.classifier2 = nn.Linear(self.bert.config.hidden_size, num_labels2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels1=None, labels2=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = self.dropout(outputs.pooler_output)\n",
    "        logits1 = self.classifier1(pooled_output)\n",
    "        logits2 = self.classifier2(pooled_output)\n",
    "        return {\"logits1\": logits1, \"logits2\": logits2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fa0aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_type_classes = len(le_type.classes_)\n",
    "num_priority_classes = len(le_priority.classes_)\n",
    "model = MultiTaskBERT(num_type_classes, num_priority_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85a91efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "409ee53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels1 = inputs.pop(\"labels1\")\n",
    "        labels2 = inputs.pop(\"labels2\")\n",
    "        outputs = model(**inputs)\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_fct(outputs[\"logits1\"], labels1)\n",
    "        loss2 = loss_fct(outputs[\"logits2\"], labels2)\n",
    "        loss = loss1 + loss2\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78844e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    ")\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7241fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='15777' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    6/15777 01:03 < 69:23:41, 0.06 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ticket_system\\myenv\\lib\\site-packages\\transformers\\trainer.py:2240\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2238\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ticket_system\\myenv\\lib\\site-packages\\transformers\\trainer.py:2555\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2548\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2549\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2551\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2553\u001b[0m )\n\u001b[0;32m   2554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2555\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2558\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2559\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2561\u001b[0m ):\n\u001b[0;32m   2562\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2563\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32md:\\ticket_system\\myenv\\lib\\site-packages\\transformers\\trainer.py:3791\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[0;32m   3789\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 3791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3793\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32md:\\ticket_system\\myenv\\lib\\site-packages\\accelerate\\accelerator.py:2473\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2471\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2473\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ticket_system\\myenv\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ticket_system\\myenv\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ticket_system\\myenv\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b51e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./ticket_classifier_model\"\n",
    "trainer.save_model(model_path)\n",
    "import pickle\n",
    "with open(\"label_encoders.pkl\", \"wb\") as f:\n",
    "    pickle.dump((le_type, le_priority), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
